{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.reshape(-1, 28*28)\n",
        "x_test = x_test.reshape(-1, 28*28)\n",
        "scaler = MinMaxScaler()\n",
        "x_train = scaler.fit_transform(x_train)\n",
        "x_test = scaler.transform(x_test)\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the model creation function\n",
        "def create_model(units=128, activation='relu'):\n",
        "    model = Sequential([\n",
        "        Dense(units, activation=activation, input_shape=(784,)),\n",
        "        Dense(units // 2, activation=activation),\n",
        "        Dense(10, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Define hyperparameters to tune\n",
        "units_values = [64, 128, 256]\n",
        "activation_values = ['relu', 'tanh', 'sigmoid']\n",
        "\n",
        "best_score = 0\n",
        "best_params = {}\n",
        "\n",
        "# Perform hyperparameter tuning\n",
        "for units in units_values:\n",
        "    for activation in activation_values:\n",
        "        print(f\"Training model with units={units} and activation={activation}\")\n",
        "        model = create_model(units=units, activation=activation)\n",
        "        model.fit(x_train, y_train, epochs=5, batch_size=32, verbose=0)\n",
        "        _, accuracy = model.evaluate(x_val, y_val)\n",
        "        if accuracy > best_score:\n",
        "            best_score = accuracy\n",
        "            best_params = {'units': units, 'activation': activation}\n",
        "\n",
        "print(\"Best Parameters:\", best_params)\n",
        "print(\"Best Score:\", best_score)\n",
        "\n",
        "# Evaluate the best model on the test set\n",
        "best_model = create_model(units=best_params['units'], activation=best_params['activation'])\n",
        "best_model.fit(x_train, y_train, epochs=5, batch_size=32, verbose=0)\n",
        "test_loss, test_acc = best_model.evaluate(x_test, y_test)\n",
        "print('Test accuracy:', test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rb3_jbp2SF-Z",
        "outputId": "aa1d338b-c8de-483f-e920-e3b1f8e9d1ea"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training model with units=64 and activation=relu\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.1019 - accuracy: 0.9699\n",
            "Training model with units=64 and activation=tanh\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.0997 - accuracy: 0.9685\n",
            "Training model with units=64 and activation=sigmoid\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.1282 - accuracy: 0.9627\n",
            "Training model with units=128 and activation=relu\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.1033 - accuracy: 0.9711\n",
            "Training model with units=128 and activation=tanh\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.0866 - accuracy: 0.9737\n",
            "Training model with units=128 and activation=sigmoid\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.1003 - accuracy: 0.9685\n",
            "Training model with units=256 and activation=relu\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.0856 - accuracy: 0.9759\n",
            "Training model with units=256 and activation=tanh\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0996 - accuracy: 0.9713\n",
            "Training model with units=256 and activation=sigmoid\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.0922 - accuracy: 0.9718\n",
            "Best Parameters: {'units': 256, 'activation': 'relu'}\n",
            "Best Score: 0.9759166836738586\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0902 - accuracy: 0.9749\n",
            "Test accuracy: 0.9749000072479248\n"
          ]
        }
      ]
    }
  ]
}